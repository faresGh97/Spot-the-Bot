{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caf02b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e2e62b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCleaner():\n",
    "    \"\"\"\n",
    "    Thai text cleaner\n",
    "    \"\"\"\n",
    "    def __init__(self):        \n",
    "        #https://omniglot.com/writing/atikamekw.htm\n",
    "        self.charchters = ['p', 't','k','s','c','tc', 'm','n','r','h', 'w','a','e','i','o']\n",
    "        self.punctuation = string.punctuation + '،' + '؛' + '؟' + '؛' + '۔' + '»' + '«' + '-'\n",
    "        self.one_space_regex = r\"\\s((\\s)(\\s+)?)?\"\n",
    "        #self.multiple_space_regex = r\"\\s+\"\n",
    "        self.text = None\n",
    "\n",
    "        self.dict_punct = dict(zip(list(self.punctuation), np.repeat(' ', len(self.punctuation))))\n",
    "        \n",
    "    def remove_punct(self, text):\n",
    "        table = str.maketrans(self.dict_punct)\n",
    "        text = text.translate(table)\n",
    "        return text\n",
    "    \n",
    "    def remove_num(self, text):\n",
    "        num_pattern = r'[\\u06F0-\\u06F9]'\n",
    "        text = re.sub(num_pattern, ' ', text)\n",
    "        return text\n",
    "    \n",
    "    def remove_spaces(self, text):\n",
    "        try:\n",
    "            #remove all whitespaces since spaces are considered as a sentence seperator in thai\n",
    "            text = re.sub(self.one_space_regex, ' ', text)\n",
    "            text = text if text[0] != ' ' else text[1:]\n",
    "            text = text if text[-1] != ' ' else text[:-1]\n",
    "            return text\n",
    "        \n",
    "        except IndexError as e:\n",
    "            return ''\n",
    "    \n",
    "    def is_not_fa_token(self, token):\n",
    "        for ch in set(token.lower()):\n",
    "            #if ord(ch) < int(self.min_ascii, 16) or ord(ch) > int(self.max_ascii, 16):\n",
    "            if ch not in self.charchters:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def remove_foreign_lang(self, text):\n",
    "        clean_text = ''\n",
    "        for token in text.split():\n",
    "            if self.is_not_fa_token(token):\n",
    "                clean_text += ' ' + token\n",
    "        return clean_text[1:]\n",
    "    \n",
    "    def clean_text(self, text):\n",
    "        text = text.lower()\n",
    "        text = self.remove_punct(text)\n",
    "        text = self.remove_num(text)\n",
    "        text = self.remove_foreign_lang(text)\n",
    "        text = self.remove_spaces(text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d1a27499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a file: file\n",
    "file = open('Pikokw.txt',mode='r')\n",
    " \n",
    "# read all lines at once\n",
    "all_of_it = file.read()\n",
    " \n",
    "# close the file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dae55067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Enko anihe atoske irapatcikan pikokw ka icinikatek. Napitc kinoskon kaie arimatc apatisiw neta nikanik anaha atos ka icinikasotc kitci ki nipahatc awesisa mekwatc ka atoskewaketc. Matci oskan kaie asini apatisiw kitci ocihakoniwitc anaha atos ka icinikasotc, arimatc kinikosiw kirika kinisiw ote nikanik. Mictikw apatan e sokaskok aka kitci natowaparik kaie kitci mirokotek. Enko tca arimatc atcapi ka apatisitc kitci matcekotcik pikokw. Nicawek icinakoniw anaha pikokw ote nikanik acitc otananik. Ote nikanik ekotc e apitc anaha atos mina ote otananik atcinikan icinikatew.\\n\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_of_it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "69b97d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "576"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_of_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f07aa44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner = TextCleaner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "520836e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = cleaner.clean_text(all_of_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cdc012b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "566"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bf06336a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'enko anihe atoske irapatcikan pikokw ka icinikatek napitc kinoskon kaie arimatc apatisiw neta nikanik anaha atos ka icinikasotc kitci ki nipahatc awesisa mekwatc ka atoskewaketc matci oskan kaie asini apatisiw kitci ocihakoniwitc anaha atos ka icinikasotc arimatc kinikosiw kirika kinisiw ote nikanik mictikw apatan e sokaskok aka kitci natowaparik kaie kitci mirokotek enko tca arimatc atcapi ka apatisitc kitci matcekotcik pikokw nicawek icinakoniw anaha pikokw ote nikanik acitc otananik ote nikanik ekotc e apitc anaha atos mina ote otananik atcinikan icinikatew'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1a5eb26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enk\n"
     ]
    }
   ],
   "source": [
    "print ('Enko'[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c512f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Atikamekw_basic_lemma():\n",
    "    self.words = {}\n",
    "    self.verbs = {}\n",
    "    self.processed_text = ''\n",
    "    \n",
    "    \n",
    "    # nouns\n",
    "    \n",
    "    #https://www.langueatikamekw.ca/grammaire/noms/locatif/\n",
    "    def replace_locatives(self, text):\n",
    "        for token in text.split():\n",
    "            if token[-2] == 'ok':\n",
    "                self.words[token]['root'] = token[:-2] + 'w'\n",
    "                self.words[token]['POS'] = 'LN'\n",
    "                #self.words[token]['type'] = 'N'\n",
    "            elif token[:-1] == 'k':\n",
    "                self.words[token]['root'] = token[:-1]\n",
    "                self.words[token]['POS'] = 'LN'\n",
    "                #self.words[token]['type'] = 'N'\n",
    "    \n",
    "    \n",
    "    #https://www.langueatikamekw.ca/grammaire/noms/le-nombre-des-noms-singulier-pluriel/\n",
    "    def remove_plurals(self, text):\n",
    "        for token in text.split():\n",
    "            if token[-2] == 'ok':\n",
    "                self.words[token]['root'] = token[:-2] + 'w'\n",
    "                self.words[token]['POS'] = 'NAP'\n",
    "                #self.words[token]['type'] = 'N'\n",
    "            elif token[-2] == 'ak':\n",
    "                self.words[token]['root'] = token[:-2]\n",
    "                self.words[token]['POS'] = 'NAP'\n",
    "            elif token[-1] == 'a':\n",
    "                self.words[token]['root'] = token[:-1]\n",
    "                self.words[token]['POS'] = 'NIP'\n",
    "                \n",
    "    \n",
    "    # possessive Pronouns\n",
    "    #befor w or constant \n",
    "    \n",
    "    #mine , yours , he's\n",
    "    possisive_pronouns_prefexis = ['ki','ni','o']\n",
    "    # befor o \n",
    "    possisive_pronouns_prefexis = ['k','n','o']\n",
    "    # before vowel\n",
    "    possisive_pronouns_prefexis = ['kit','nit','ot']\n",
    "    \n",
    "    # notre mine and hes = ni possisive\n",
    "    ni + word + in/an\n",
    "    # notre notre  mine and yours \n",
    "    ki + word + in/o\n",
    "    # your (plural) \n",
    "    ki + word + iwaw\n",
    "    #thier \n",
    "    o + word + iwaw\n",
    "    o+ word + iwa \n",
    "    o + word + aw\n",
    "    # his other froms \n",
    "    o + word + iriw\n",
    "    \n",
    "    # someone propoerty  indefinite format \n",
    "    o + word + nan or awik\n",
    "    \n",
    "    #surboviatif \n",
    "    \n",
    "    #possisive comes befor the plural\n",
    "    \n",
    "                \n",
    "    stop-words = ['kotahik','awihik','kotak','awik', 'wirawaw','wir','ninan',\n",
    "                  'kirano','kirawaw','nin','kir' , 'kekwan']\n",
    "    ask_question_stop_words =['awin','awiritake','kekwan' ,'tan' ]\n",
    "    presentative_stop_words = ['enko','namaiew']\n",
    "    alternative_stop_words = ['kotak']\n",
    "    demonstrative_stop_words =['nahwe','ohki' , 'nohwe', 'niheriw','neheriw', 'neriw']\n",
    "    \n",
    "    \n",
    "    #verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1de8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nouns to indicate if the profession is male or female\n",
    "male_female_words_of_profession = ['iskwew' # female\n",
    " ,'iriniw' #male\n",
    ", 'irinikwew' #male or female \n",
    "]\n",
    "\n",
    "#verbs to indicate  profession\n",
    "male_female_verbs_of_profession = [ 'iriniwin','iskwewin','riniskwewin']\n",
    "\n",
    "# indicate the genere of an animal \n",
    "\n",
    "male_Female_particular_animals = ['noce' #female\n",
    "                                 ,'nape' # male\n",
    "                                 ,]\n",
    "\n",
    "#NOUNS\n",
    "\n",
    "# they come by this order po -> p-> di -> loc\n",
    "\n",
    "\n",
    "possisive_pref = ['kit','nit','ot' , 'ki','ni','o', 'k','n','o']\n",
    "\n",
    "possisive_suff = ['inan' , 'ino' ,  'iwaw' , 'iwa' ,'aw','iriw','nan', 'awik' , 'im']\n",
    "\n",
    "\n",
    "\n",
    "plural_suff = ['a','ak','ok>w']\n",
    "\n",
    "diminutif_suff = ['icic', 'ocic']\n",
    "#diminutif_suff = ['ic', 'cic']\n",
    "\n",
    "locative_suff = ['ik', 'ok>w']\n",
    "\n",
    "#those last two we can add together\n",
    "obviativ_suff = ['iw','riw','a']\n",
    "\n",
    "surobviatif = ['iriw','riw']\n",
    "\n",
    "\n",
    "derivation_suffix = ['an','ekin','apo','api','apiskw']\n",
    "\n",
    "#PRONOUNS\n",
    " \n",
    "perosonal_pron = ['nin' , 'kir' , 'wir']\n",
    "indefinant_pron = ['awik' , 'kekwan' , 'kotak']\n",
    "interogatice_pron = ['awin' , 'kekwan' , 'tan' , 'tanta', 'tante','tan apitc']\n",
    "\n",
    "personal_pron_prefixes = ['ni','ki','nit','kit']\n",
    "personal_pron_independant = ['nin','kir','wir','ninan','kirano','kirawaw','wirawaw']\n",
    "personal_pron_independant_priority = ['ninctam','kirctam','wirctam','nirctaminan','kirctamiwaw','wirctamiwaw']\n",
    "\n",
    "#\n",
    "demostrative_words = ['nahwe', 'ohwa','ohwe','oma','nahwe','anahwe'\n",
    "                     ,'naha','anaha','na','ohki','niki','neki'\n",
    "                     ,'nihe','ohwi','nehe','anehe','nihi','neta','nete']\n",
    "\n",
    "#time\n",
    "#repetation\n",
    "#comparing\n",
    "#connectors\n",
    "#subbordinate + verb\n",
    "#expressing countite\n",
    "#Modality of action (way of doing)\n",
    "#proximity\n",
    "#spacial-oriantation\n",
    "#mark of interrogation\n",
    "#intergection\n",
    "particules = ['Aptic','minawatc','mocak','nama wiskat','nac','kinowec','ko' \n",
    "             ,'kiapatc','kiapatci','kiapatc peikwa','koski','oscamec','awocamec',\n",
    "             'kekat','wiec','kirowe','nota','orina','tapicoktc','patok','mia','towi',\n",
    "             'acitc','kirica','aima','aric','kaie',\n",
    "             'e','ka','epwamoci','esko','ickwa','kitci','nota','wetci',\n",
    "             'notc','memantcic','micta','tipi','orina','tepirak',\n",
    "             'tekaci','pekatc','mamar'\n",
    "             ,'warowik','pecotcik','ota','ote','neta','nete','nte',\n",
    "             'icpimik','notc','opimera','okitc','cipa','pitc','nikanik','otananik','orowitimik','pitakamik',\n",
    "             'la','a','aia',\n",
    "             'ekocka','icine']\n",
    "\n",
    "# 'kecpin' == if \n",
    "# 'kitci' == for\n",
    "# 'e' == that\n",
    "# 'wetci' == for\n",
    "#' tan' == what\n",
    "#'tan apitc' == when\n",
    "#'kekwan wetci' = why\n",
    "# 'aka' == negatuve\n",
    "# 'ka' == relative\n",
    "\n",
    "preverbes_for_immidiatly = ['ta','wi','ka','ki']\n",
    "#VERBS\n",
    "\n",
    "#verbs_suff = ['an','in', 'w','n','ano','awaw','ok']\n",
    "# verbs_suff_AI_independent = ['n','nan', 'nano','nawaw','wok'] ->['w']\n",
    "# verbs_suff_TI_independent = ['en','am','an','ano','awaw','ok'] -> ['am']\n",
    "# verb_suff_AI_conjunctive = ['n','ian','an','in','iin','tc','ak','iak','iakw','kw','ikw','iekw','ekw','tcik'] ->['w']\n",
    "# verb_suff_AI_imperative = ['kw','an','kan','kekw','tan'] ->['w']\n",
    "# verb_suf_TI_imperative = ['amokw','eta','ekan','amokan','ameta'] -> ['am']\n",
    "# verb_suf_TA_imperative = ['ici','inan','icikw','icinan','icikan','icikanan','icikekw','icikanan'] -> ['ew']\n",
    "\n",
    "\n",
    "\n",
    "lexical_final = ['ote','ska','kowi','h','aso','acte','ckow','pw']\n",
    "abstract_final = ['aia','cin','t','n','r','h']\n",
    "\n",
    "doutfull_suffix = ['take']\n",
    "subjonctive_suffix = ['e']\n",
    "\n",
    "imperfect_suffix = ['tai','pan']\n",
    "past_suffix = 'ki'\n",
    "future_after_verb = ['ka','kata','ickwa']\n",
    "\n",
    "preform_lexical = ['miro','kice','matci','micta','mata','kakike']\n",
    "\n",
    "# reflexiv oneself ['itiso']\n",
    "# recepcioncal each other ['ito']\n",
    "\n",
    "#derivation \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47832f0",
   "metadata": {},
   "source": [
    "VII: verb inanime intransitive\n",
    "\n",
    "VAI  : anime intransitive\n",
    "\n",
    "VTA : verb transitive anime\n",
    "\n",
    "VTI : verb transitive inanime\n",
    "\n",
    "VTI2 : verb transitive inanime \n",
    "\n",
    "#########\n",
    "\n",
    "\n",
    "01 independant indicatif present\n",
    "\n",
    "03 independant indicatif impeerfect\n",
    "\n",
    "09 independant dubitatif present\n",
    "\n",
    "10 independant dubitatif past\n",
    "\n",
    "11a conjonctive indicatif present\n",
    "\n",
    "12a conjonctive subjonctif\n",
    "\n",
    "12b conjonctive iteratif \n",
    "\n",
    "13 conjonctive imperfrect\n",
    "\n",
    "14 concojonctive dubitatif\n",
    "\n",
    "15 conjonctive dubitatifg imperfect\n",
    "\n",
    "17a imperfect indicative present\n",
    "\n",
    "17b imperfect indicative future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a811c823",
   "metadata": {},
   "outputs": [],
   "source": [
    "vai_01 = ['n','nawaw','nano','nan','wok','riw','riwa']\n",
    "vai_03 = ['tai','tawaw','tanano','tai','tan','pan','panak','ripan']\n",
    "vai_09 = ['natake' , 'nawatake','nanotake','natake','nanatake','take','takenak','ritake','ritakena']\n",
    "vai_10 = ['nakopan','nawakopan','nanokopan','nanakopan','kopan','wakopan','rikopan','rikopana']\n",
    "vai_11 = ['in','iekw','ikw','ian','ika','tc','tcik','ritci','ritci']\n",
    "vai_12a = ['ine','iekwe','ikwe','iane','iake','te','wate','rite','ritena']\n",
    "#vai_12b = vai_12a\n",
    "vai_13 =['ipan','iekopan','ikopan','iapan','iakipan','span','waspan','rispan','rispana']\n",
    "vai_14 = ['wonen','wewokwen','wokwen','wanen','waken','kwen','wekwen','rikwen','rikwena']\n",
    "vai_15 = ['wopanen','wekopanen','wokopanen','wapanen','wakipanen','kopanen','wakopanen','rikopanen','rikopanena']\n",
    "vai_17a = ['kw','tan']\n",
    "vai_17b = ['kan','kekw','tan']\n",
    "\n",
    "vii_01 = ['o','iw','iwa','a','riw','riwa']\n",
    "vii_03 = ['pan','pana','ripan','ripana']\n",
    "vii_09 = ['take','takena','ritake','ritakena']\n",
    "vii_10 = ['kopan','kopana','rikopan','rikopana']\n",
    "vi_11 = ['k','ki','rik','riki']\n",
    "vi_12a = ['ke','kawe','rike','rikawe']\n",
    "#vi_12b = vi_12a\n",
    "vi_13 = ['kipan','kipana','rikipan','rikipana']\n",
    "vi_14 = ['kwen','kwena','rikwen','rikwena','ikwen','ikwena']\n",
    "vi_15 = ['kopanen','kopanena','rikopanen']\n",
    "\n",
    "\n",
    "vta_01 = ['in','itin','inan','itinan','inawaw','itinawaw',\n",
    "         'imawaw','imikowaw','anano','ikonano','ananowok', 'ikonanowok', 'imananowa', 'imikonano'\n",
    "         , 'aw','ikw','awok','ikok','imawa', 'imikw'\n",
    "         , 'anan' , 'ikonan' ,'ananak', 'ikonanak','imanana','imikonan'\n",
    "         , 'awaw' , 'ikowaw','awawok','ikowawok'\n",
    "         ,'ew','ewok','imew','imewok','imeriw','iko','ikowok','eriw','eriwa','ikoriw','ikoriwa']\n",
    "vta_03 = ['itai', 'ititai','itan', 'itinan','itawaw', 'itinaw','atanano','ikotanano','atananowok','ikotananowok'\n",
    "         'atai', 'ikotai','ataiik','ikoktaiik','atan','ikotan','atananak','ikotananak'\n",
    "         'atawaw','ikotawaw','atawawok','ikotawawok','epan','epanak','ikopan','ikowapanak'\n",
    "         ,'eripan','eripana','ikoripan','ikor']\n",
    "vta_09 = ['inatake' , 'inanatake', 'inawatake', 'itinatake','itinanatake'\n",
    "         ,'itinawatake','ananotake','ananotakenak','ikonanotake','ikonanotakenak'\n",
    "         ,'atake', 'atakenak' , 'ikonatakenak', 'ananatake','ananatakenak'\n",
    "         ,'ikonanatakenak','awatake','awatakenak','ikotake','ikowatake','ikotakenak',\n",
    "         'ikowatakenak','etake','etakena','ikotakena','eritake','eritakena','ikoritake','ikoritakena']\n",
    "vta_10 = ['inakopan', 'inanakopan','inawakopan','itinakopan','itinanakopan'\n",
    "         ,'itinawakopan','ananokopan','ananokopanak','ikonanokopan','ikonanokopanak'\n",
    "         ,'akopan','akopanak','ikokopan','ikokopanak','akopan','ananakopank','ikonanakopan'\n",
    "         ,'ananakopanak','ikonanakopanak','awakopan','awakopanak','ikokopan'\n",
    "         ,'ikokopanak','ikowakopan','ekopan','ekopana','ikokopan','ikokopan','ikowakopan',\n",
    "         'ikowakopana','erikopan','erikopana','ikorikopan','ikorikopana']\n",
    "\n",
    "vta_11 = ['iin','iak','iekw','itan','itak','itakok','imeko',\n",
    "         'okw','okok','imoko','imitako','itokw','itokok','imitoko'\n",
    "         ,'ak','akik','imaki','itc','itcik','imitci','akitc','imitc'\n",
    "         ,'akitcik','imitcik','imakitci','imtci','atc','iskw',\n",
    "         'atcik','imatci','iskik','imiski','itakw','itakok','ekw','ekok',\n",
    "         'atc','atcik','imatc','imatcik','imaritci','eritci','ewaritci',\n",
    "         'ikoritci','ikowaritci','kotc','ikotcik']\n",
    "\n",
    "vta_12 = ['iine','itaane','iake','iekwe','itake','itakokwe',\n",
    "         'okwe','okwawe','itokwe','itokwawe','amake','akawe',\n",
    "         'ikote','ikowate','imite','imitawe','ate','akite','atawe','iske','iskawe'\n",
    "         ,'ewekwe','etawe','itakwe','itakawe','amate','awate','ikote','ikowate',\n",
    "         'arite','ariwate','ariwatena','ikorite','ikoriwate']\n",
    "vta_13 = ['ipan','iekopan','iakipan','iekopan','itapan','itakipan','itakokipan'\n",
    "         , 'itakipan','okopan','okwapan','itakopan','itokwapan','akipan','akwapan','ispan',\n",
    "         'iwaspan','akitipan','akitwapan','atipan','atwapan','ewekopan','ewekwapan','aspan',\n",
    "         'aspana','awaspan','awaspana','arispan','arispana','imitipan','imitwapan','iskipan',\n",
    "         'iskwapan','itakopan','itakwapan','ikospan','ikowaspana',\n",
    "         'ikorispan','ikorwiwarispan']\n",
    "vta_14 = ['iwonen','iwakwen','iwekwen','itawonen','itakokwen','owokwen', 'owokwenak'\n",
    "         ,'awoken','awokenak','awakiten','awakitenak','awoten','awotenak','ewekwen','ewekwenak',\n",
    "         'akwen','awakwen','itokwen','itokwenak','ikwen','iwakwen','itkowen','itokwenak',\n",
    "         'iskwen','iskwaken','itakwen','itawenak','ikokwen','ikowakwen',\n",
    "         'ikowakwen','arikwen','arikwena','ikorikwen','ikorikwena']\n",
    "\n",
    "vta_15 = ['iwopanen','iakopanen','iekopanen','itawopanen','itakopanen',\n",
    "         'owokopanen','awokopanenak','awokipanen','awokipanenak','awokitipanen',\n",
    "         'awokitipanenak','awotipanen','awotipanenak','ewekopanen','ewekopanenak',\n",
    "         'ikokopanenak','ikokopanen','iskwakopanen','iskopanen','iamitokopanenak','iamitokopanen',\n",
    "         'iwakopanen','ikopanen','itokokopanenak','itokokopanen']\n",
    "\n",
    "vta_17_a = ['ici','icinan','icikw','imik','imakw','atan','atanak','imatan','i','ik','im','akw','akok']\n",
    "vta_17_b  = ['icikan','icikanan','icikekw','imakanak','imakan','akan','akanak','imakan','akekw','akekok']\n",
    "\n",
    "\n",
    "vti_01 = ['en','enawaw','enano','enan','am','amok','amiriw','amiriwa','w','wa','riw','riwawa']\n",
    "vti_03 = ['etai','etawaw','etano','etai','etan','amopan','amopank','amiripan','amiripana','pan','pana','ripan','ripana']\n",
    "vti_09 = ['enatake','enawatake','enanotake','amotake','amotakenak','amiritake',\n",
    "         'amiritakena','take','takena','ritakena','ritakena']\n",
    "vti_10 = ['enakopan','enawakopan','enanokopan','enanakopan','amokopan','amowakopan','amirikopan','amirikopana']\n",
    "vti_11 = ['aman','amekw','amokw','amak','ak','akik','amiritci','k','ki','riki']\n",
    "vti_12a = ['amane','amekwe','amiekwe','amokwe','amoikwe','amane','amake','amane','amote','amowate','amirite','amiritena']\n",
    "#vti_12b = vit_12a\n",
    "vti_13 = ['amopan','amekopan','amokopan','amapan','amakipan','akipan','akwapan',\n",
    "          'amirispan', 'amirispana']\n",
    "vti_14 = ['amowonen','amwewokwen','amowokwen','amowaken','amokwen','amowakwen','amirikwen','amirikwena']\n",
    "vti_15 = ['amowopanen','amokwekopanen','amokopanen','amowapanen','amowakipanen','amokopanen','amowkopanen','amirikopanen','amirikopanena']\n",
    "vti_17a = ['a','amokw','eta']\n",
    "vti_17b = ['ekan','amokan']\n",
    "\n",
    "\n",
    "\n",
    "vti2_01 = ['n','nawaw','nano','nan','w','wok','riw','riwa','o','iw','iwa']\n",
    "vti2_03 = ['tai','tawaw','tanano','tai','tan','pan','panak','ripan','ripana','pan','ipana','opan','opana']\n",
    "vti2_09 = ['natake','nawatake','nanotake',\n",
    "          'nanatake','take','takenak','ritake',\n",
    "         'ritakena','otake','otakena','oritakena','oritakena']\n",
    "vti2_10 = ['nakopan','nawakopan','nanokopan','nakopan','kopan','wakopan','rikopan','rikopana']\n",
    "vti2_11 = ['in','iekw','ikw','ian','iak','tc','tcik','ritci','ki','niki','nik']\n",
    "vti2_12a = ['ine','iekwe','ikwe','iane','iake','te','wate','rite','ritena']\n",
    "#vti_12b = vit_12a\n",
    "vti_13 = ['ipan','iekopan','ikopan','iapan','iakipan','span','waspan',\n",
    "          'rispan', 'rispana']\n",
    "vti_14 = ['wonen','wewokwen','wokwen','wanen','waken','kwen','wakwen','rikwena','rikwena']\n",
    "vti_15 = ['wopanen','wekopanen','wokopanen','wapanen','wakipanen','kopanen','wakopanen','rikopanen','rikopanena']\n",
    "vti_17a = ['kw','tan']\n",
    "vti_17b = ['kan','kekw','nano']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b9a221",
   "metadata": {},
   "source": [
    "!pip install multilingual-pdf2text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "06498c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:multilingual_pdf2text.doc2img.parse_document:Parsing document from pdf to image\n",
      "INFO:multilingual_pdf2text.doc2img.parse_document:Unable to get page count. Is poppler installed and in PATH?\n",
      "INFO:multilingual_pdf2text.ocr.image_to_text:Extracting text from images via OCR\n"
     ]
    }
   ],
   "source": [
    "from multilingual_pdf2text.pdf2text import PDF2Text\n",
    "from multilingual_pdf2text.models.docum\n",
    "ent_model.document import Document\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "pdf_document = Document(\n",
    "        document_path=\"eScholarship UC item 7fk44815.pdf\",\n",
    "        language='eng'\n",
    "        )\n",
    "pdf2text = PDF2Text(document=pdf_document)\n",
    "content = pdf2text.extract()\n",
    "with open('output_file.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(f\"{content}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3ff98a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
